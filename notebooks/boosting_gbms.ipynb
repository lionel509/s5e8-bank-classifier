{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b175f18",
   "metadata": {},
   "source": [
    "# Boosting GBMs Category - Kaggle Playground Series S5E8\n",
    "\n",
    "**Category**: Boosting Gradient Boosting Machines  \n",
    "**Sub-models**: GradientBoostingClassifier, XGBoost, LightGBM, CatBoost  \n",
    "**Split Strategy**: 70/30 stratified split  \n",
    "**Cross-Validation**: 5-fold StratifiedKFold  \n",
    "**Random Seed**: 42  \n",
    "**Artifact Paths**: outputs/boosting_gbms/  \n",
    "\n",
    "This notebook compares different gradient boosting variants using the same data preprocessing and evaluation protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673cbcc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:49:50.036640Z",
     "iopub.status.busy": "2025-08-09T23:49:50.036030Z",
     "iopub.status.idle": "2025-08-09T23:50:32.937891Z",
     "shell.execute_reply": "2025-08-09T23:50:32.935721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] xgboost not available: \n",
      "XGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed\n",
      "    - vcomp140.dll or libgomp-1.dll for Windows\n",
      "    - libomp.dylib for Mac OSX\n",
      "    - libgomp.so for Linux and other UNIX-like OSes\n",
      "    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "\n",
      "Error message(s): [\"dlopen(/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <8E129FE8-EF1C-38EA-A9CF-202782564052> /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/lib-dynload/../../libomp.dylib' (no such file), '/opt/homebrew/Caskroom/miniconda/base/bin/../lib/libomp.dylib' (no such file)\"]\n",
      "\n",
      "[WARN] lightgbm not available: dlopen(/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\n",
      "  Referenced from: <D44045CD-B874-3A27-9A61-F131D99AACE4> /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/lightgbm/lib/lib_lightgbm.dylib\n",
      "  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/lib-dynload/../../libomp.dylib' (no such file), '/opt/homebrew/Caskroom/miniconda/base/bin/../lib/libomp.dylib' (no such file)\n",
      "[WARN] shap not available: Numba needs NumPy 2.2 or less. Got NumPy 2.3.\n",
      "[ENV] Python 3.13.5  Numpy 2.3.2  Pandas 2.3.1\n",
      "[ENV] XGBoost=False  LightGBM=False  CatBoost=True  SHAP=False\n"
     ]
    }
   ],
   "source": [
    "# Safe imports and availability checks (no internet installs)\n",
    "import os, json, random, pickle, warnings, sys, platform, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score, accuracy_score, precision_score,\n",
    "    recall_score, roc_curve, precision_recall_curve, log_loss, auc\n",
    ")\n",
    "\n",
    "# Optional libs\n",
    "HAS_XGB = HAS_LGBM = HAS_CATBOOST = False\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] xgboost not available:\", e)\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    HAS_LGBM = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] lightgbm not available:\", e)\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    HAS_CATBOOST = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] catboost not available:\", e)\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] shap not available:\", e)\n",
    "    HAS_SHAP = False\n",
    "\n",
    "print(f\"[ENV] Python {platform.python_version()}  Numpy {np.__version__}  Pandas {pd.__version__}\")\n",
    "print(f\"[ENV] XGBoost={HAS_XGB}  LightGBM={HAS_LGBM}  CatBoost={HAS_CATBOOST}  SHAP={HAS_SHAP}\")\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b66cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:32.944880Z",
     "iopub.status.busy": "2025-08-09T23:50:32.943695Z",
     "iopub.status.idle": "2025-08-09T23:50:33.019279Z",
     "shell.execute_reply": "2025-08-09T23:50:33.017110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     feature_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m train_df.columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     11\u001b[39m     X = train_df[feature_cols]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     y = \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded Kaggle dataset. Features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feature_cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Rows=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'target'"
     ]
    }
   ],
   "source": [
    "# Load and prepare data (with fallback)\n",
    "print(\"Loading data...\")\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "train_path = '../playground-series-s5e8/train.csv'\n",
    "test_path = '../playground-series-s5e8/test.csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    feature_cols = [c for c in train_df.columns if c not in ['id', 'target']]\n",
    "    X = train_df[feature_cols]\n",
    "    y = train_df['target']\n",
    "    print(f\"Loaded Kaggle dataset. Features={len(feature_cols)} Rows={len(train_df)}\")\n",
    "else:\n",
    "    print(\"[WARN] Kaggle files not found. Using a synthetic binary classification dataset.\")\n",
    "    X, y = make_classification(n_samples=3000, n_features=20, n_informative=10, n_redundant=4,\n",
    "                               n_classes=2, weights=[0.6, 0.4], random_state=42)\n",
    "    X = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "X_train_pool, X_test_holdout, y_train_pool, y_test_holdout = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Train pool: {X_train_pool.shape}, Test holdout: {X_test_holdout.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce6cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:33.026595Z",
     "iopub.status.busy": "2025-08-09T23:50:33.025791Z",
     "iopub.status.idle": "2025-08-09T23:50:33.040339Z",
     "shell.execute_reply": "2025-08-09T23:50:33.038586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 4 GBM variants:\n",
      "  - GradientBoosting_sklearn\n",
      "  - XGBoost_hist\n",
      "  - LightGBM\n",
      "  - CatBoost\n"
     ]
    }
   ],
   "source": [
    "# Define GBM models and their hyperparameter grids (fast version)\n",
    "models_config = {}\n",
    "\n",
    "# Always include sklearn GradientBoosting\n",
    "models_config['GradientBoosting_sklearn'] = {\n",
    "    'estimator': GradientBoostingClassifier(random_state=42),\n",
    "    'param_grid': {\n",
    "        'classifier__learning_rate': [0.1],\n",
    "        'classifier__max_depth': [3],\n",
    "        'classifier__n_estimators': [100]\n",
    "    },\n",
    "    'use_pipeline': True\n",
    "}\n",
    "\n",
    "if HAS_XGB:\n",
    "    models_config['XGBoost_hist'] = {\n",
    "        'estimator': xgb.XGBClassifier(\n",
    "            tree_method='hist',\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            n_estimators=150,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=4\n",
    "        ),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [150],\n",
    "            'classifier__learning_rate': [0.1],\n",
    "            'classifier__max_depth': [4]\n",
    "        },\n",
    "        'use_pipeline': True\n",
    "    }\n",
    "\n",
    "if HAS_LGBM:\n",
    "    models_config['LightGBM'] = {\n",
    "        'estimator': LGBMClassifier(\n",
    "            objective='binary', n_estimators=150, learning_rate=0.1, max_depth=-1, random_state=42\n",
    "        ),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [150],\n",
    "            'classifier__learning_rate': [0.1]\n",
    "        },\n",
    "        'use_pipeline': True\n",
    "    }\n",
    "\n",
    "if HAS_CATBOOST:\n",
    "    models_config['CatBoost'] = {\n",
    "        'estimator': CatBoostClassifier(\n",
    "            verbose=False, random_state=42, iterations=200, learning_rate=0.1, depth=6, loss_function='Logloss'\n",
    "        ),\n",
    "        'param_grid': {\n",
    "            'classifier__iterations': [200],\n",
    "            'classifier__learning_rate': [0.1],\n",
    "            'classifier__depth': [6]\n",
    "        },\n",
    "        'use_pipeline': True\n",
    "    }\n",
    "\n",
    "print(f\"Configured {len(models_config)} GBM variants:\")\n",
    "for name in models_config.keys():\n",
    "    print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428812ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:33.046133Z",
     "iopub.status.busy": "2025-08-09T23:50:33.045308Z",
     "iopub.status.idle": "2025-08-09T23:50:33.058430Z",
     "shell.execute_reply": "2025-08-09T23:50:33.057433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "def create_pipeline(estimator, use_pipeline=True):\n",
    "    \"\"\"Create preprocessing pipeline - GBMs typically don't need scaling\"\"\"\n",
    "    if use_pipeline:\n",
    "        return Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('classifier', estimator)\n",
    "        ])\n",
    "    else:\n",
    "        # For some models that handle missing values natively\n",
    "        return estimator\n",
    "\n",
    "def get_probabilities(estimator, X):\n",
    "    \"\"\"Get probabilities from estimator\"\"\"\n",
    "    return estimator.predict_proba(X)[:, 1]\n",
    "\n",
    "def compute_metrics(y_true, y_prob, threshold=0.5):\n",
    "    \"\"\"Compute all evaluation metrics\"\"\"\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'roc_auc': roc_auc_score(y_true, y_prob),\n",
    "        'average_precision': average_precision_score(y_true, y_prob),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'logloss': log_loss(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "def find_best_threshold(y_true, y_prob):\n",
    "    \"\"\"Find best threshold using Youden's J statistic\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    j_scores = tpr - fpr\n",
    "    best_idx = np.argmax(j_scores)\n",
    "    return thresholds[best_idx]\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba5c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:33.121569Z",
     "iopub.status.busy": "2025-08-09T23:50:33.120941Z",
     "iopub.status.idle": "2025-08-09T23:50:39.191386Z",
     "shell.execute_reply": "2025-08-09T23:50:39.190012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[START] GradientBoosting_sklearn\n",
      "[INFO] Parameter grid: {'classifier__learning_rate': [0.1], 'classifier__max_depth': [3], 'classifier__n_estimators': [100]}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__learning_rate=0.1, classifier__max_depth=3, classifier__n_estimators=100; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__learning_rate=0.1, classifier__max_depth=3, classifier__n_estimators=100; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier__learning_rate=0.1, classifier__max_depth=3, classifier__n_estimators=100; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Grid search complete.\n",
      "[BEST] params: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 100} score: 0.96365\n",
      "[METRICS] {\n",
      "  \"auc\": 0.9770893290446363,\n",
      "  \"ap\": 0.9720942399467696,\n",
      "  \"f1\": 0.9313186813186813,\n",
      "  \"accuracy\": 0.9444444444444444,\n",
      "  \"precision\": 0.9287671232876712,\n",
      "  \"recall\": 0.9338842975206612,\n",
      "  \"logloss\": 0.20294365616273274\n",
      "}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m train_idx, test_idx \u001b[38;5;129;01min\u001b[39;00m cv.split(X_train_pool, y_train_pool):\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Quick CV curve (no refit) for visualization consistency\u001b[39;00m\n\u001b[32m     54\u001b[39m     X_tr, X_te = X_train_pool.iloc[train_idx], X_train_pool.iloc[test_idx]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     y_tr, y_te = \u001b[43my_train_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m[train_idx], y_train_pool.iloc[test_idx]\n\u001b[32m     56\u001b[39m     est = grid_search.best_estimator_\n\u001b[32m     57\u001b[39m     prob_cv = est.predict_proba(X_te)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# Main evaluation loop\n",
    "results = {}\n",
    "all_cv_results = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, cfg in models_config.items():\n",
    "    print(f\"\\n{'='*60}\\n[START] {model_name}\")\n",
    "    estimator = cfg['estimator']\n",
    "    pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')), ('classifier', estimator)]) if cfg['use_pipeline'] else estimator\n",
    "    \n",
    "    print(\"[INFO] Parameter grid:\", cfg['param_grid'])\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=cfg['param_grid'],\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=1,\n",
    "        verbose=2,\n",
    "        refit=True,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    grid_search.fit(X_train_pool, y_train_pool)\n",
    "    print(\"[DONE] Grid search complete.\")\n",
    "    print(\"[BEST] params:\", grid_search.best_params_, \"score:\", round(grid_search.best_score_, 5))\n",
    "    \n",
    "    # Evaluate on holdout\n",
    "    y_prob = grid_search.predict_proba(X_test_holdout)[:, 1]\n",
    "    best_thresh = None\n",
    "    try:\n",
    "        best_thresh = find_best_threshold(y_test_holdout, y_prob)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Threshold search failed:\", e)\n",
    "        best_thresh = 0.5\n",
    "    y_pred = (y_prob >= best_thresh).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        'auc': roc_auc_score(y_test_holdout, y_prob),\n",
    "        'ap': average_precision_score(y_test_holdout, y_prob),\n",
    "        'f1': f1_score(y_test_holdout, y_pred),\n",
    "        'accuracy': accuracy_score(y_test_holdout, y_pred),\n",
    "        'precision': precision_score(y_test_holdout, y_pred),\n",
    "        'recall': recall_score(y_test_holdout, y_pred),\n",
    "        'logloss': log_loss(y_test_holdout, y_prob)\n",
    "    }\n",
    "    print(\"[METRICS]\", json.dumps(metrics, indent=2))\n",
    "    \n",
    "    # Store curves for plotting\n",
    "    fpr, tpr, _ = roc_curve(y_test_holdout, y_prob)\n",
    "    prec, rec, _ = precision_recall_curve(y_test_holdout, y_prob)\n",
    "    cv_roc_curves = []\n",
    "    for train_idx, test_idx in cv.split(X_train_pool, y_train_pool):\n",
    "        # Quick CV curve (no refit) for visualization consistency\n",
    "        X_tr, X_te = X_train_pool.iloc[train_idx], X_train_pool.iloc[test_idx]\n",
    "        y_tr, y_te = y_train_pool.iloc[train_idx], y_train_pool.iloc[test_idx]\n",
    "        est = grid_search.best_estimator_\n",
    "        prob_cv = est.predict_proba(X_te)[:, 1]\n",
    "        fpr_cv, tpr_cv, _ = roc_curve(y_te, prob_cv)\n",
    "        cv_roc_curves.append((fpr_cv, tpr_cv))\n",
    "    \n",
    "    model_dir = f\"../outputs/boosting_gbms/{model_name.replace(' ', '_')}\"\n",
    "    os.makedirs(f\"{model_dir}/figures\", exist_ok=True)\n",
    "    os.makedirs(f\"{model_dir}/models\", exist_ok=True)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score_cv': grid_search.best_score_,\n",
    "        'holdout_metrics': metrics,\n",
    "        'fpr': fpr, 'tpr': tpr, 'prec': prec, 'rec': rec,\n",
    "        'cv_roc_curves': cv_roc_curves,\n",
    "        'model_dir': model_dir,\n",
    "        'best_estimator': grid_search.best_estimator_\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All GBM models evaluated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e3af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:39.217806Z",
     "iopub.status.busy": "2025-08-09T23:50:39.217165Z",
     "iopub.status.idle": "2025-08-09T23:50:39.233663Z",
     "shell.execute_reply": "2025-08-09T23:50:39.232107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All artifacts saved!\n"
     ]
    }
   ],
   "source": [
    "# Save artifacts for each model\n",
    "for model_name, model_results in results.items():\n",
    "    model_dir = model_results['model_dir']\n",
    "    \n",
    "    # Save CV metrics\n",
    "    cv_df = pd.DataFrame(model_results['cv_metrics'])\n",
    "    \n",
    "    # Add summary statistics\n",
    "    summary_stats = []\n",
    "    for metric in ['roc_auc', 'average_precision', 'f1', 'accuracy', 'precision', 'recall', 'logloss']:\n",
    "        summary_stats.append({\n",
    "            'fold': 'mean',\n",
    "            metric: cv_df[metric].mean(),\n",
    "            'threshold': cv_df['threshold'].mean()\n",
    "        })\n",
    "        summary_stats.append({\n",
    "            'fold': 'std',\n",
    "            metric: cv_df[metric].std(),\n",
    "            'threshold': cv_df['threshold'].std()\n",
    "        })\n",
    "    \n",
    "    cv_summary_df = pd.concat([cv_df, pd.DataFrame(summary_stats)], ignore_index=True)\n",
    "    cv_summary_df.to_csv(f\"{model_dir}/logs/cv_metrics.csv\", index=False)\n",
    "    \n",
    "    # Save test metrics\n",
    "    with open(f\"{model_dir}/logs/test_metrics.json\", 'w') as f:\n",
    "        json.dump(model_results['test_metrics'], f, indent=2)\n",
    "    \n",
    "    # Save model (handle different formats)\n",
    "    final_pipeline = create_pipeline(models_config[model_name]['estimator'], models_config[model_name]['use_pipeline'])\n",
    "    grid_search_final = GridSearchCV(\n",
    "        final_pipeline, models_config[model_name]['param_grid'], \n",
    "        cv=cv, scoring='roc_auc', n_jobs=-1\n",
    "    )\n",
    "    grid_search_final.fit(X_train_pool, y_train_pool)\n",
    "    \n",
    "    if 'XGBoost' in model_name:\n",
    "        # Save XGBoost in native format\n",
    "        if hasattr(grid_search_final.best_estimator_, 'named_steps'):\n",
    "            xgb_model = grid_search_final.best_estimator_.named_steps['classifier']\n",
    "        else:\n",
    "            xgb_model = grid_search_final.best_estimator_\n",
    "        xgb_model.save_model(f\"{model_dir}/models/final_model.json\")\n",
    "    elif 'LightGBM' in model_name:\n",
    "        # Save LightGBM in native format\n",
    "        if hasattr(grid_search_final.best_estimator_, 'named_steps'):\n",
    "            lgb_model = grid_search_final.best_estimator_.named_steps['classifier']\n",
    "        else:\n",
    "            lgb_model = grid_search_final.best_estimator_\n",
    "        lgb_model.booster_.save_model(f\"{model_dir}/models/final_model.txt\")\n",
    "    elif 'CatBoost' in model_name:\n",
    "        # Save CatBoost in native format\n",
    "        if hasattr(grid_search_final.best_estimator_, 'named_steps'):\n",
    "            cb_model = grid_search_final.best_estimator_.named_steps['classifier']\n",
    "        else:\n",
    "            cb_model = grid_search_final.best_estimator_\n",
    "        cb_model.save_model(f\"{model_dir}/models/final_model.cbm\")\n",
    "    \n",
    "    # Also save as pickle for consistency\n",
    "    with open(f\"{model_dir}/models/final_model.pkl\", 'wb') as f:\n",
    "        pickle.dump(grid_search_final.best_estimator_, f)\n",
    "    \n",
    "    print(f\"Artifacts saved for {model_name}\")\n",
    "\n",
    "print(\"\\nAll artifacts saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a5b34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:39.239950Z",
     "iopub.status.busy": "2025-08-09T23:50:39.239286Z",
     "iopub.status.idle": "2025-08-09T23:50:39.254591Z",
     "shell.execute_reply": "2025-08-09T23:50:39.253090Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 95)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<tokenize>:95\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexcept Exception as e:\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "HAS_SHAP = globals().get('HAS_SHAP', False)\n",
    "print(f'[INFO] SHAP available: {HAS_SHAP}')\n",
    "# Generate figures for each model with GBM-specific plots\n",
    "for model_name, model_results in results.items():\n",
    "    model_dir = model_results['model_dir']\n",
    "    \n",
    "    print(f\"Generating figures for {model_name}...\")\n",
    "    \n",
    "    # 1. ROC Curve with CV mean and std\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    for fpr, tpr in model_results['cv_roc_curves']:\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    \n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    \n",
    "    plt.plot(mean_fpr, mean_tpr, 'b-', \n",
    "             label=f'Mean ROC (AUC = {np.mean([cv[\"roc_auc\"] for cv in model_results[\"cv_metrics\"]]):.3f} ± {np.std([cv[\"roc_auc\"] for cv in model_results[\"cv_metrics\"]]):.3f})')\n",
    "    plt.fill_between(mean_fpr, mean_tpr - std_tpr, mean_tpr + std_tpr, alpha=0.2, color='blue')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_dir}/figures/roc_cv.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Load final model for feature importance and SHAP\n",
    "    with open(f\"{model_dir}/models/final_model.pkl\", 'rb') as f:\n",
    "        final_model = pickle.load(f)\n",
    "    \n",
    "    # Get the actual estimator (handle pipeline)\n",
    "    if hasattr(final_model, 'named_steps'):\n",
    "        estimator = final_model.named_steps['classifier']\n",
    "        # Transform data through pipeline preprocessing\n",
    "        X_transformed = final_model.named_steps['imputer'].transform(X_train_pool)\n",
    "    else:\n",
    "        estimator = final_model\n",
    "        X_transformed = X_train_pool.fillna(X_train_pool.median())\n",
    "    \n",
    "    # 2. Feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if hasattr(estimator, 'feature_importances_'):\n",
    "        importances = estimator.feature_importances_\n",
    "        indices = np.argsort(importances)[-20:]  # Top 20\n",
    "        \n",
    "        plt.barh(range(len(indices)), importances[indices], alpha=0.7)\n",
    "        plt.yticks(range(len(indices)), [feature_cols[i] for i in indices])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top 20 Feature Importances - {model_name}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Feature importance not available', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title(f'Feature Importance - {model_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_dir}/figures/feature_importance.png\", dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. SHAP summary plot (for tree-based models)\n",
    "    try:\n",
    "        print(f\"  Generating SHAP plot for {model_name}...\")\n",
    "        \n",
    "        # Sample data for SHAP (computational efficiency)\n",
    "        sample_size = min(1000, len(X_transformed))\n",
    "        sample_indices = np.random.choice(len(X_transformed), sample_size, replace=False)\n",
    "        X_sample = X_transformed[sample_indices] if isinstance(X_transformed, np.ndarray) else X_transformed.iloc[sample_indices]\n",
    "        \n",
    "        # Create SHAP explainer\n",
    "        if 'XGBoost' in model_name or 'LightGBM' in model_name or 'CatBoost' in model_name or 'GradientBoosting' in model_name:\n",
    "            explainer = # SHAP usage disabled when not available\n",
    "shap.TreeExplainer(estimator)\n",
    "            shap_values = explainer.shap_values(X_sample)\n",
    "            \n",
    "            # Handle different SHAP value formats\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_values = shap_values[1]  # For binary classification, take positive class\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            # SHAP usage disabled when not available\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_cols, show=False)\n",
    "            plt.title(f'SHAP Summary - {model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{model_dir}/figures/shap_summary.png\", dpi=200, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    SHAP plot failed for {model_name}: {str(e)}\")\n",
    "        # Create placeholder\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.5, f'SHAP plot failed:\\n{str(e)}', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title(f'SHAP Summary - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{model_dir}/figures/shap_summary.png\", dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Generate other standard plots (confusion matrix, calibration, etc.)\n",
    "    # ... (similar to previous notebooks)\n",
    "\n",
    "print(\"All figures generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376ed5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T23:50:39.261156Z",
     "iopub.status.busy": "2025-08-09T23:50:39.260793Z",
     "iopub.status.idle": "2025-08-09T23:50:39.431698Z",
     "shell.execute_reply": "2025-08-09T23:50:39.430499Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_370/1321048972.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m         \u001b[33m'artifacts_path'\u001b[39m: model_results[\u001b[33m'model_dir'\u001b[39m]\n\u001b[32m     18\u001b[39m     })\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Sort by test AUC\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m summary_df = pd.DataFrame(summary_data).sort_values(\u001b[33m'test_auc'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Save summary\u001b[39;00m\n\u001b[32m     24\u001b[39m os.makedirs(\u001b[33m'../outputs/boosting_gbms'\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/pandas/util/_decorators.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m                     msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    328\u001b[39m                     FutureWarning,\n\u001b[32m    329\u001b[39m                     stacklevel=find_stack_level(),\n\u001b[32m    330\u001b[39m                 )\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   6908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   6909\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   6910\u001b[39m \n\u001b[32m   6911\u001b[39m             by = by[\u001b[32m0\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m6912\u001b[39m             k = self._get_label_or_level_values(by, axis=axis)\n\u001b[32m   6913\u001b[39m \n\u001b[32m   6914\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   6915\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1846\u001b[39m                 .get_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   1847\u001b[39m                 ._values\n\u001b[32m   1848\u001b[39m             )\n\u001b[32m   1849\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1850\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1851\u001b[39m \n\u001b[32m   1852\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1853\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'test_auc'"
     ]
    }
   ],
   "source": [
    "# Create summary table and final results\n",
    "summary_data = []\n",
    "\n",
    "for model_name, model_results in results.items():\n",
    "    test_metrics = model_results['test_metrics']\n",
    "    cv_metrics = model_results['cv_metrics']\n",
    "    \n",
    "    summary_data.append({\n",
    "        'model': model_name,\n",
    "        'test_auc': test_metrics['roc_auc'],\n",
    "        'test_ap': test_metrics['average_precision'],\n",
    "        'test_f1': test_metrics['f1'],\n",
    "        'test_accuracy': test_metrics['accuracy'],\n",
    "        'cv_auc_mean': np.mean([cv['roc_auc'] for cv in cv_metrics]),\n",
    "        'cv_auc_std': np.std([cv['roc_auc'] for cv in cv_metrics]),\n",
    "        'best_params': str(model_results['best_params']),\n",
    "        'artifacts_path': model_results['model_dir']\n",
    "    })\n",
    "\n",
    "# Sort by test AUC\n",
    "summary_df = pd.DataFrame(summary_data).sort_values('test_auc', ascending=False)\n",
    "\n",
    "# Save summary\n",
    "os.makedirs('../outputs/boosting_gbms', exist_ok=True)\n",
    "summary_df.to_csv('../outputs/boosting_gbms/summary.csv', index=False)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BOOSTING GBMs CATEGORY - FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nRanked by Test AUC:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx, row in summary_df.iterrows():\n",
    "    print(f\"{row['model']:30s} | AUC: {row['test_auc']:.4f} | AP: {row['test_ap']:.4f} | F1: {row['test_f1']:.4f}\")\n",
    "    print(f\"{'':30s} | CV AUC: {row['cv_auc_mean']:.4f}±{row['cv_auc_std']:.4f}\")\n",
    "    print(f\"{'':30s} | Artifacts: {row['artifacts_path']}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nBest Model: {summary_df.iloc[0]['model']}\")\n",
    "print(f\"Best Test AUC: {summary_df.iloc[0]['test_auc']:.4f}\")\n",
    "print(f\"\\nAll results saved to: ../outputs/boosting_gbms/\")\n",
    "print(f\"Summary saved to: ../outputs/boosting_gbms/summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
