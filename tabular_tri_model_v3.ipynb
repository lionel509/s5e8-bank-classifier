{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e51b41e",
   "metadata": {},
   "source": [
    "# Tri-Model v3 (Parallel) â€” MLP + TabTransformer + FT-Transformer\n",
    "\n",
    "\n",
    "Trains three models in parallel with K-Fold CV, compares OOF AUCs, auto warm-starts from best prior run if found, and creates an ensemble submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "418c8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIG ---\n",
    "COMPETITION_NAME=\"playground-series-s5e8\"\n",
    "ID_COL=\"id\"; TARGET_COL=\"y\"\n",
    "TRAIN_PATH=\"playground-series-s5e8/train.csv\"; TEST_PATH=\"playground-series-s5e8/test.csv\"\n",
    "N_SPLITS=5; RANDOM_SEED=2025\n",
    "\n",
    "BATCH_SIZE=4096; EPOCHS=100; PATIENCE=12\n",
    "BASE_LR=1e-3; WEIGHT_DECAY=1e-5\n",
    "USE_CLASS_WEIGHTS=True; MIN_LR=1e-5\n",
    "COSINE_T0=10; COSINE_T_MULT=2; GRAD_CLIP=1.0\n",
    "USE_SWA=True; SWA_START_EPOCH=10; SWA_LR=5e-4\n",
    "\n",
    "# Fine-tuned per-arch params\n",
    "A_HIDDEN=[1024,512,256,128]; A_DROPOUT=0.25; A_EMB_DROPOUT=0.05; A_INPUT_DROPOUT=0.05\n",
    "B_D_MODEL=192; B_N_HEAD=8; B_N_LAYERS=4; B_DROPOUT=0.2; B_EMB_DROPOUT=0.05; B_INPUT_DROPOUT=0.05; B_MLP_HEAD=[512,256]\n",
    "C_D_MODEL=256; C_N_HEAD=8; C_N_LAYERS=3; C_DROPOUT=0.2; C_EMB_DROPOUT=0.05; C_INPUT_DROPOUT=0.05; C_MLP_HEAD=[512,256]\n",
    "\n",
    "AUTO_WARM_START=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df76ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps | pin_memory: False | run: runs/2025-08-12_11-02-40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- IMPORTS & ENV ---\n",
    "import os, gc, time, math, random, json\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "import multiprocessing as mp\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "use_mps = hasattr(torch.backends,\"mps\") and torch.backends.mps.is_available()\n",
    "has_cuda = torch.cuda.is_available()\n",
    "if has_cuda: DEVICE=torch.device(\"cuda\")\n",
    "elif use_mps: DEVICE=torch.device(\"mps\")\n",
    "else: DEVICE=torch.device(\"cpu\")\n",
    "PIN_MEM = True if DEVICE.type==\"cuda\" else False\n",
    "\n",
    "RUN_STAMP=time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "ROOT_DIR=Path(f\"runs/{RUN_STAMP}\"); ROOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Device:\", DEVICE, \"| pin_memory:\", PIN_MEM, \"| run:\", ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1abe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- DATA PREP ---\n",
    "train=pd.read_csv(TRAIN_PATH); test=pd.read_csv(TEST_PATH)\n",
    "assert TARGET_COL in train and ID_COL in train and ID_COL in test\n",
    "\n",
    "feature_cols=[c for c in train.columns if c not in [TARGET_COL,ID_COL]]\n",
    "missing=[c for c in feature_cols if c not in test.columns]; assert not missing, f\"Missing in test: {missing}\"\n",
    "\n",
    "obj_cols=[c for c in feature_cols if train[c].dtype=='object']\n",
    "lowcard=[c for c in feature_cols if str(train[c].dtype).startswith('int') and train[c].nunique()<=30]\n",
    "cat_cols=sorted(list(set(obj_cols+lowcard)))\n",
    "num_cols=sorted([c for c in feature_cols if c not in cat_cols])\n",
    "\n",
    "RARE_NAME=\"__RARE__\"; MIN_CAT_COUNT=25\n",
    "def apply_rare(s, m=MIN_CAT_COUNT):\n",
    "    v=s.value_counts(); rare=v[v<m].index\n",
    "    return s.where(~s.isin(rare), RARE_NAME)\n",
    "\n",
    "encoders={}\n",
    "for c in cat_cols:\n",
    "    tr=apply_rare(train[c].astype(str)); te=apply_rare(test[c].astype(str))\n",
    "    le=LabelEncoder(); le.fit(pd.concat([tr,te],axis=0).fillna(\"NA\"))\n",
    "    encoders[c]=le; train[c]=le.transform(tr.fillna(\"NA\")); test[c]=le.transform(te.fillna(\"NA\"))\n",
    "\n",
    "scaler=None\n",
    "if len(num_cols)>0:\n",
    "    scaler=StandardScaler()\n",
    "    train[num_cols]=scaler.fit_transform(train[num_cols]); test[num_cols]=scaler.transform(test[num_cols])\n",
    "\n",
    "cat_cardinalities=[int(train[c].nunique()) for c in cat_cols]\n",
    "y=train[TARGET_COL].values.astype(np.float32)\n",
    "\n",
    "meta=dict(cat_cols=cat_cols,num_cols=num_cols,cat_cardinalities=cat_cardinalities,feature_cols=feature_cols)\n",
    "(json.dump(meta, open(ROOT_DIR/'data_meta.json','w'), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663e12de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- MODELS & HELPERS ---\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, df, y=None, num_cols=None, cat_cols=None):\n",
    "        self.num=df[num_cols].values.astype(np.float32) if num_cols else np.zeros((len(df),0),np.float32)\n",
    "        self.cat=df[cat_cols].values.astype(np.int64) if cat_cols else np.zeros((len(df),0),np.int64)\n",
    "        self.y=y.astype(np.float32) if y is not None else None\n",
    "    def __len__(self): return len(self.num)\n",
    "    def __getitem__(self, i):\n",
    "        if self.y is None: return self.num[i], self.cat[i]\n",
    "        return self.num[i], self.cat[i], self.y[i]\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, mode=\"max\", min_delta=1e-6):\n",
    "        self.p=patience; self.mode=mode; self.md=min_delta\n",
    "        self.best=-np.inf if mode==\"max\" else np.inf; self.count=0; self.state=None\n",
    "    def step(self, metric, model):\n",
    "        imp=(metric>self.best+self.md) if self.mode==\"max\" else (metric<self.best-self.md)\n",
    "        if imp: self.best=metric; self.count=0; self.state={k:v.cpu().clone() for k,v in model.state_dict().items()}; return True\n",
    "        self.count+=1; return False\n",
    "    def stop(self): return self.count>=self.p\n",
    "\n",
    "def epoch_loop(model, loader, crit, opt=None, dev=DEVICE, clip=None):\n",
    "    train=(opt is not None); model.train() if train else model.eval()\n",
    "    losses=[]; preds=[]; targs=[]\n",
    "    for b in loader:\n",
    "        if train: x_num,x_cat,y=b\n",
    "        else:\n",
    "            try: x_num,x_cat,y=b\n",
    "            except: x_num,x_cat=b; y=None\n",
    "        x_num=x_num.to(dev); x_cat=x_cat.to(dev); \n",
    "        if y is not None: y=y.to(dev)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logit=model(x_num,x_cat); prob=torch.sigmoid(logit); loss=crit(logit,y) if y is not None else None\n",
    "        if train:\n",
    "            opt.zero_grad(); loss.backward(); \n",
    "            if clip is not None: nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "        if loss is not None: losses.append(loss.item()); targs.append(y.detach().cpu().numpy())\n",
    "        preds.append(prob.detach().cpu().numpy())\n",
    "    preds=np.concatenate(preds) if preds else np.array([])\n",
    "    y_true=np.concatenate(targs) if targs else None\n",
    "    return (float(np.mean(losses)) if losses else None), preds, y_true\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, num_dim, cats, hidden, drop=0.25, emb_drop=0.05, in_drop=0.05):\n",
    "        super().__init__()\n",
    "        self.hc=len(cats)>0; self.hn=num_dim>0\n",
    "        self.in_drop=nn.Dropout(in_drop) if in_drop>0 and self.hn else nn.Identity()\n",
    "        if self.hc:\n",
    "            self.embs=nn.ModuleList([nn.Embedding(c, int(min(64,max(4,round(1.6*(c**0.56)))))) for c in cats])\n",
    "            self.emb_drop=nn.Dropout(emb_drop) if emb_drop>0 else nn.Identity()\n",
    "            emb_total=sum([e.embedding_dim for e in self.embs])\n",
    "        else:\n",
    "            self.embs=None; self.emb_drop=nn.Identity(); emb_total=0\n",
    "        in_dim=(num_dim if self.hn else 0)+emb_total\n",
    "        L=[]; p=in_dim\n",
    "        for h in hidden: L+=[nn.Linear(p,h), nn.BatchNorm1d(h), nn.GELU(), nn.Dropout(drop)]; p=h\n",
    "        L+=[nn.Linear(p,1)]; self.mlp=nn.Sequential(*L)\n",
    "    def forward(self, x_num, x_cat):\n",
    "        feats=[]\n",
    "        if self.hc:\n",
    "            em=[emb(x_cat[:,i]) for i,emb in enumerate(self.embs)]\n",
    "            cf=torch.cat(em,dim=1); feats.append(self.emb_drop(cf))\n",
    "        if self.hn: feats.append(self.in_drop(x_num))\n",
    "        x=torch.cat(feats,dim=1) if len(feats)>1 else feats[0]\n",
    "        return self.mlp(x).squeeze(1)\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_dim, cats, d_model, nhead, nlayers, drop, emb_drop, in_drop, head_layers):\n",
    "        super().__init__()\n",
    "        self.hc=len(cats)>0; self.hn=num_dim>0\n",
    "        self.in_drop=nn.Dropout(in_drop) if in_drop>0 and self.hn else nn.Identity()\n",
    "        if self.hc:\n",
    "            self.cat_embs=nn.ModuleList([nn.Embedding(c, d_model) for c in cats])\n",
    "            self.emb_drop=nn.Dropout(emb_drop) if emb_drop>0 else nn.Identity()\n",
    "        else:\n",
    "            self.cat_embs=None; self.emb_drop=nn.Identity()\n",
    "        enc_layer=nn.TransformerEncoderLayer(d_model=d_model,nhead=nhead,dropout=drop,batch_first=True,activation='gelu')\n",
    "        self.encoder=nn.TransformerEncoder(enc_layer,num_layers=nlayers)\n",
    "        self.num_proj=nn.Linear(num_dim,d_model) if self.hn else None\n",
    "        L=[]; in_dim=d_model + (d_model if self.hn else 0)\n",
    "        for h in head_layers: L+=[nn.Linear(in_dim,h), nn.BatchNorm1d(h), nn.GELU(), nn.Dropout(drop)]; in_dim=h\n",
    "        L+=[nn.Linear(in_dim,1)]; self.head=nn.Sequential(*L)\n",
    "    def forward(self, x_num, x_cat):\n",
    "        feats=[]\n",
    "        if self.hc:\n",
    "            toks=[e(x_cat[:,i]).unsqueeze(1) for i,e in enumerate(self.cat_embs)]\n",
    "            tok=torch.cat(toks,dim=1); tok=self.emb_drop(tok)\n",
    "            enc=self.encoder(tok); feats.append(enc.mean(dim=1))\n",
    "        if self.hn: feats.append(self.in_drop(self.num_proj(x_num)))\n",
    "        x=torch.cat(feats,dim=1) if len(feats)>1 else feats[0]\n",
    "        return self.head(x).squeeze(1)\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, num_dim, cats, d_model, nhead, nlayers, drop, emb_drop, in_drop, head_layers):\n",
    "        super().__init__()\n",
    "        self.nd=num_dim; self.cd=len(cats)\n",
    "        self.num_proj=nn.Linear(1,d_model) if num_dim>0 else None\n",
    "        self.num_drop=nn.Dropout(in_drop) if in_drop>0 else nn.Identity()\n",
    "        self.cat_embs=nn.ModuleList([nn.Embedding(c,d_model) for c in cats]) if len(cats)>0 else None\n",
    "        self.emb_drop=nn.Dropout(emb_drop) if emb_drop>0 else nn.Identity()\n",
    "        self.cls=nn.Parameter(torch.zeros(1,1,d_model))\n",
    "        enc_layer=nn.TransformerEncoderLayer(d_model=d_model,nhead=nhead,dropout=drop,batch_first=True,activation='gelu')\n",
    "        self.encoder=nn.TransformerEncoder(enc_layer,num_layers=nlayers)\n",
    "        L=[]; in_dim=d_model\n",
    "        for h in head_layers: L+=[nn.Linear(in_dim,h), nn.BatchNorm1d(h), nn.GELU(), nn.Dropout(drop)]; in_dim=h\n",
    "        L+=[nn.Linear(in_dim,1)]; self.head=nn.Sequential(*L)\n",
    "    def forward(self, x_num, x_cat):\n",
    "        B = x_num.shape[0] if x_num.ndim>0 else x_cat.shape[0]\n",
    "        toks=[]\n",
    "        if self.nd>0:\n",
    "            x=x_num.unsqueeze(-1); x=self.num_proj(x); x=self.num_drop(x); toks.append(x)\n",
    "        if self.cd>0:\n",
    "            ct=[e(x_cat[:,i]).unsqueeze(1) for i,e in enumerate(self.cat_embs)]\n",
    "            ct=torch.cat(ct,dim=1); ct=self.emb_drop(ct); toks.append(ct)\n",
    "        tok=torch.cat(toks,dim=1) if len(toks)>1 else toks[0]\n",
    "        cls=self.cls.expand(B,1,-1); tok=torch.cat([cls,tok],dim=1)\n",
    "        enc=self.encoder(tok); return self.head(enc[:,0,:]).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df22bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best prior run: (PosixPath('runs/2025-08-12_09-12-57'), 0.9625154905879971)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- WARM-START SCAN ---\n",
    "def find_best_prior_run():\n",
    "    base=Path(\"runs\")\n",
    "    if not base.exists(): return (None, None)\n",
    "    best=-1.0; bestp=None\n",
    "    for p in sorted(base.iterdir()):\n",
    "        if not p.is_dir(): continue\n",
    "        oof=p/\"oof_predictions.csv\"; metrics=p/\"metrics.csv\"\n",
    "        try:\n",
    "            if oof.exists():\n",
    "                df=pd.read_csv(oof)\n",
    "                if \"oof\" in df and TARGET_COL in df:\n",
    "                    auc=roc_auc_score(df[TARGET_COL], df[\"oof\"])\n",
    "                    if auc>best: best=auc; bestp=p\n",
    "            elif metrics.exists():\n",
    "                m=pd.read_csv(metrics)\n",
    "                if \"best_val_auc\" in m: \n",
    "                    val=m[\"best_val_auc\"].dropna().max()\n",
    "                    if val>best: best=val; bestp=p\n",
    "        except Exception: pass\n",
    "    return (bestp, best)\n",
    "\n",
    "BEST_PRIOR=find_best_prior_run() if AUTO_WARM_START else (None,None)\n",
    "print(\"Best prior run:\", BEST_PRIOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9826e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TRAIN FUNCTION (for multiprocessing) ---\n",
    "def train_model(model_name, arch_cfg, root_dir, device_str, pin_mem, seed=RANDOM_SEED):\n",
    "    set_seed(seed)\n",
    "    import torch, torch.nn as nn\n",
    "    from torch.utils.data import DataLoader\n",
    "    import numpy as np, pandas as pd\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "    from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
    "    from pathlib import Path\n",
    "    import json, time\n",
    "\n",
    "    DEVICE=torch.device(device_str)\n",
    "\n",
    "    meta=json.load(open(root_dir/'data_meta.json'))\n",
    "    cat_cols=meta[\"cat_cols\"]; num_cols=meta[\"num_cols\"]; cat_cardinalities=meta[\"cat_cardinalities\"]; feature_cols=meta[\"feature_cols\"]\n",
    "    \n",
    "    # Use the already preprocessed train/test data from global scope\n",
    "    global train, test, y\n",
    "    train_data = train.copy()\n",
    "    test_data = test.copy()\n",
    "    y_data = y.copy()\n",
    "\n",
    "    skf=StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "    mdir=root_dir/model_name; (mdir/\"folds\").mkdir(parents=True, exist_ok=True); (mdir/\"figs\").mkdir(exist_ok=True)\n",
    "\n",
    "    pos_weight=None\n",
    "    if USE_CLASS_WEIGHTS:\n",
    "        pr=train_data[TARGET_COL].mean(); pw=max(1e-6,(1.0-pr)/max(1e-6,pr))\n",
    "        pos_weight=torch.tensor([pw],dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    oof=np.zeros(len(train_data),dtype=np.float32)\n",
    "    test_preds=np.zeros((len(test_data),N_SPLITS),dtype=np.float32)\n",
    "\n",
    "    warm_dir=None\n",
    "    if AUTO_WARM_START and BEST_PRIOR and BEST_PRIOR[0] is not None:\n",
    "        warm_dir=BEST_PRIOR[0]/model_name/\"folds\"\n",
    "        if not warm_dir.exists(): \n",
    "            wd=BEST_PRIOR[0]/\"folds\"\n",
    "            warm_dir=wd if wd.exists() else None\n",
    "\n",
    "    for fold,(tr_idx,va_idx) in enumerate(skf.split(train_data[feature_cols], train_data[TARGET_COL])):\n",
    "        tr_df=train_data.iloc[tr_idx].reset_index(drop=True); va_df=train_data.iloc[va_idx].reset_index(drop=True)\n",
    "        tr_ds=TabDataset(tr_df, tr_df[TARGET_COL].values, num_cols, cat_cols)\n",
    "        va_ds=TabDataset(va_df, va_df[TARGET_COL].values, num_cols, cat_cols)\n",
    "        te_ds=TabDataset(test_data, None, num_cols, cat_cols)\n",
    "        tr_loader=DataLoader(tr_ds,batch_size=BATCH_SIZE,shuffle=True,num_workers=0,pin_memory=pin_mem)\n",
    "        va_loader=DataLoader(va_ds,batch_size=BATCH_SIZE,shuffle=False,num_workers=0,pin_memory=pin_mem)\n",
    "        te_loader=DataLoader(te_ds,batch_size=BATCH_SIZE,shuffle=False,num_workers=0,pin_memory=pin_mem)\n",
    "\n",
    "        # Build model\n",
    "        if model_name==\"modelA\":\n",
    "            model=MLPNet(len(num_cols), cat_cardinalities, A_HIDDEN, A_DROPOUT, A_EMB_DROPOUT, A_INPUT_DROPOUT).to(DEVICE)\n",
    "        elif model_name==\"modelB\":\n",
    "            model=TabTransformer(len(num_cols), cat_cardinalities, B_D_MODEL,B_N_HEAD,B_N_LAYERS,B_DROPOUT,B_EMB_DROPOUT,B_INPUT_DROPOUT,B_MLP_HEAD).to(DEVICE)\n",
    "        else:\n",
    "            model=FTTransformer(len(num_cols), cat_cardinalities, C_D_MODEL,C_N_HEAD,C_N_LAYERS,C_DROPOUT,C_EMB_DROPOUT,C_INPUT_DROPOUT,C_MLP_HEAD).to(DEVICE)\n",
    "\n",
    "        crit=nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
    "        opt=torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "        sch=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=COSINE_T0, T_mult=COSINE_T_MULT, eta_min=MIN_LR)\n",
    "        swa_model=AveragedModel(model) if USE_SWA else None\n",
    "        swa_sch=SWALR(opt, swa_lr=SWA_LR) if USE_SWA else None\n",
    "\n",
    "        # Warm start\n",
    "        if warm_dir is not None and (warm_dir/f\"fold_{fold}\"/\"model.pth\").exists():\n",
    "            try:\n",
    "                state=torch.load(warm_dir/f\"fold_{fold}\"/\"model.pth\", map_location=\"cpu\")\n",
    "                model.load_state_dict(state, strict=False)\n",
    "                print(f\"[{model_name}] Warm-started fold {fold}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{model_name}] Warm-start failed:\", e)\n",
    "\n",
    "        es=EarlyStopper(patience=PATIENCE,mode=\"max\"); best=-np.inf; logs=[]\n",
    "        for epoch in range(1,EPOCHS+1):\n",
    "            tr_loss,_,_=epoch_loop(model,tr_loader,crit,opt,DEVICE,GRAD_CLIP)\n",
    "            va_loss,va_pred,va_true=epoch_loop(model,va_loader,crit,None,DEVICE)\n",
    "            va_auc=roc_auc_score(va_true,va_pred)\n",
    "            sch.step(epoch+fold)\n",
    "            if USE_SWA and epoch>=SWA_START_EPOCH: swa_model.update_parameters(model); swa_sch.step()\n",
    "            logs.append(dict(epoch=epoch,train_loss=tr_loss,val_loss=va_loss,val_auc=float(va_auc),lr=float(opt.param_groups[0]['lr'])))\n",
    "            if es.step(va_auc, model): best=va_auc\n",
    "            if es.stop(): \n",
    "                print(f\"[{model_name}] fold {fold} early stop @ {epoch}, best={best:.6f}\"); break\n",
    "\n",
    "        if USE_SWA:\n",
    "            # Custom BN update for tabular models\n",
    "            swa_model.train()\n",
    "            with torch.no_grad():\n",
    "                for x_num, x_cat, _ in tr_loader:\n",
    "                    x_num = x_num.to(DEVICE)\n",
    "                    x_cat = x_cat.to(DEVICE)\n",
    "                    swa_model(x_num, x_cat)\n",
    "            \n",
    "            # Evaluate SWA model\n",
    "            swa_model.eval()\n",
    "            with torch.no_grad():\n",
    "                p=[]; t=[]\n",
    "                for x_num,x_cat,yb in va_loader:\n",
    "                    x_num=x_num.to(DEVICE); x_cat=x_cat.to(DEVICE)\n",
    "                    logits=swa_model(x_num,x_cat); p.append(torch.sigmoid(logits).cpu().numpy()); t.append(yb.numpy())\n",
    "                p=np.concatenate(p); t=np.concatenate(t); auc_swa=roc_auc_score(t,p)\n",
    "            if auc_swa>=best:\n",
    "                model.load_state_dict(swa_model.state_dict()); best=auc_swa; print(f\"[{model_name}] SWA kept/improved {best:.6f}\")\n",
    "\n",
    "        fold_dir=mdir/\"folds\"/f\"fold_{fold}\"; fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pd.DataFrame(logs).to_csv(fold_dir/\"train_log.csv\", index=False)\n",
    "        torch.save(model.state_dict(), fold_dir/\"model.pth\")\n",
    "\n",
    "        _, va_pred, va_true = epoch_loop(model,va_loader,crit,None,DEVICE); oof[va_idx]=va_pred.squeeze()\n",
    "        _, te_pred, _ = epoch_loop(model,te_loader,crit,None,DEVICE); test_preds[:,fold]=te_pred.squeeze()\n",
    "\n",
    "        fig,ax=plt.subplots(); RocCurveDisplay.from_predictions(va_true,va_pred,ax=ax); ax.set_title(f\"{model_name} Fold {fold} ROC\")\n",
    "        fig.savefig(fold_dir/\"roc_curve.png\",bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "        df=pd.read_csv(fold_dir/\"train_log.csv\")\n",
    "        fig,ax=plt.subplots(); ax.plot(df[\"epoch\"],df[\"train_loss\"],label=\"train\"); ax.plot(df[\"epoch\"],df[\"val_loss\"],label=\"val\")\n",
    "        ax.legend(); ax.set_title(f\"{model_name} Fold {fold} Loss\"); fig.savefig(fold_dir/\"loss_curve.png\",bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "        fig,ax=plt.subplots(); ax.plot(df[\"epoch\"],df[\"val_auc\"],label=\"val_auc\"); ax.legend(); ax.set_title(f\"{model_name} Fold {fold} AUC\")\n",
    "        fig.savefig(fold_dir/\"val_auc_curve.png\",bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    oof_auc=roc_auc_score(y_data,oof); print(f\"[{model_name}] OOF AUC:\", oof_auc)\n",
    "    pd.DataFrame({ID_COL:train_data[ID_COL].values,\"oof\":oof,TARGET_COL:y_data}).to_csv(mdir/\"oof_predictions.csv\",index=False)\n",
    "    sub=pd.DataFrame({ID_COL:test_data[ID_COL].values,TARGET_COL:test_preds.mean(axis=1)}); sub.to_csv(mdir/\"submission.csv\",index=False)\n",
    "\n",
    "    fig,ax=plt.subplots(); RocCurveDisplay.from_predictions(y_data,oof,ax=ax); ax.set_title(f\"{model_name} OOF ROC\")\n",
    "    fig.savefig(mdir/\"figs\"/\"oof_roc_curve.png\",bbox_inches=\"tight\"); plt.close(fig)\n",
    "    json.dump({\"oof_auc\":float(oof_auc)}, open(mdir/\"score.json\",\"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7e4e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting modelA...\n",
      "[modelA] Warm-start failed: Error(s) in loading state_dict for MLPNet:\n",
      "\tsize mismatch for mlp.0.weight: copying a param with shape torch.Size([512, 47]) from checkpoint, the shape in current model is torch.Size([1024, 47]).\n",
      "\tsize mismatch for mlp.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for mlp.9.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for mlp.9.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "[modelA] Warm-start failed: Error(s) in loading state_dict for MLPNet:\n",
      "\tsize mismatch for mlp.0.weight: copying a param with shape torch.Size([512, 47]) from checkpoint, the shape in current model is torch.Size([1024, 47]).\n",
      "\tsize mismatch for mlp.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for mlp.9.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for mlp.9.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([256]).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name,cfg \u001b[38;5;129;01min\u001b[39;00m [(\u001b[33m\"\u001b[39m\u001b[33mmodelA\u001b[39m\u001b[33m\"\u001b[39m,archA),(\u001b[33m\"\u001b[39m\u001b[33mmodelB\u001b[39m\u001b[33m\"\u001b[39m,archB),(\u001b[33m\"\u001b[39m\u001b[33mmodelC\u001b[39m\u001b[33m\"\u001b[39m,archC)]:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸš€ Starting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPIN_MEM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRANDOM_SEED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸŽ‰ All models finished!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_name, arch_cfg, root_dir, device_str, pin_mem, seed)\u001b[39m\n\u001b[32m     75\u001b[39m es=EarlyStopper(patience=PATIENCE,mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m); best=-np.inf; logs=[]\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     tr_loss,_,_=\u001b[43mepoch_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtr_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcrit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mGRAD_CLIP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     va_loss,va_pred,va_true=epoch_loop(model,va_loader,crit,\u001b[38;5;28;01mNone\u001b[39;00m,DEVICE)\n\u001b[32m     79\u001b[39m     va_auc=roc_auc_score(va_true,va_pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mepoch_loop\u001b[39m\u001b[34m(model, loader, crit, opt, dev, clip)\u001b[39m\n\u001b[32m     23\u001b[39m train=(opt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m); model.train() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m model.eval()\n\u001b[32m     24\u001b[39m losses=[]; preds=[]; targs=[]\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mb\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:159\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcollate_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections.abc.Mapping):\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/torch/utils/data/_utils/collate.py:293\u001b[39m, in \u001b[36mcollate_numpy_scalar_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcollate_numpy_scalar_fn\u001b[39m(\n\u001b[32m    289\u001b[39m     batch,\n\u001b[32m    290\u001b[39m     *,\n\u001b[32m    291\u001b[39m     collate_fn_map: Optional[\u001b[38;5;28mdict\u001b[39m[Union[\u001b[38;5;28mtype\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m, ...]], Callable]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    292\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- SEQUENTIAL TRAINING (Notebook-Safe) ---\n",
    "archA=dict(hidden=A_HIDDEN, drop=A_DROPOUT, emb_drop=A_EMB_DROPOUT, in_drop=A_INPUT_DROPOUT)\n",
    "archB=dict(d_model=B_D_MODEL,nhead=B_N_HEAD,nlayers=B_N_LAYERS,drop=B_DROPOUT,emb_drop=B_EMB_DROPOUT,in_drop=B_INPUT_DROPOUT,head_layers=B_MLP_HEAD)\n",
    "archC=dict(d_model=C_D_MODEL,nhead=C_N_HEAD,nlayers=C_N_LAYERS,drop=C_DROPOUT,emb_drop=C_EMB_DROPOUT,in_drop=C_INPUT_DROPOUT,head_layers=C_MLP_HEAD)\n",
    "\n",
    "json.dump(archA, open(ROOT_DIR/\"arch_modelA.json\",\"w\"), indent=2)\n",
    "json.dump(archB, open(ROOT_DIR/\"arch_modelB.json\",\"w\"), indent=2)\n",
    "json.dump(archC, open(ROOT_DIR/\"arch_modelC.json\",\"w\"), indent=2)\n",
    "\n",
    "# Train models sequentially (safer for notebooks)\n",
    "for name,cfg in [(\"modelA\",archA),(\"modelB\",archB),(\"modelC\",archC)]:\n",
    "    print(f\"\\nðŸš€ Starting {name}...\")\n",
    "    train_model(name, cfg, ROOT_DIR, str(DEVICE), PIN_MEM, RANDOM_SEED)\n",
    "    print(f\"âœ… {name} completed!\")\n",
    "    \n",
    "print(\"ðŸŽ‰ All models finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f685c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/2025-08-12_11-01-44/modelA/score.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mmodelA\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mmodelB\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mmodelC\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      4\u001b[39m     mdir=ROOT_DIR/name\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     sc=json.load(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmdir\u001b[49m\u001b[43m/\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      6\u001b[39m     rows.append({\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m:name,\u001b[33m\"\u001b[39m\u001b[33moof_auc\u001b[39m\u001b[33m\"\u001b[39m:sc[\u001b[33m\"\u001b[39m\u001b[33moof_auc\u001b[39m\u001b[33m\"\u001b[39m],\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m:mdir.as_posix()})\n\u001b[32m      7\u001b[39m     s=pd.read_csv(mdir/\u001b[33m\"\u001b[39m\u001b[33msubmission.csv\u001b[39m\u001b[33m\"\u001b[39m).set_index(ID_COL).rename(columns={TARGET_COL:\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'runs/2025-08-12_11-01-44/modelA/score.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- COMPARISON + ENSEMBLE ---\n",
    "rows=[]; subs=[]; oofs=[]\n",
    "for name in [\"modelA\",\"modelB\",\"modelC\"]:\n",
    "    mdir=ROOT_DIR/name\n",
    "    sc=json.load(open(mdir/\"score.json\"))\n",
    "    rows.append({\"model\":name,\"oof_auc\":sc[\"oof_auc\"],\"path\":mdir.as_posix()})\n",
    "    s=pd.read_csv(mdir/\"submission.csv\").set_index(ID_COL).rename(columns={TARGET_COL:f\"y_{name}\"})\n",
    "    subs.append(s)\n",
    "    o=pd.read_csv(mdir/\"oof_predictions.csv\")[[ID_COL,\"oof\"]].set_index(ID_COL).rename(columns={\"oof\":f\"oof_{name}\"})\n",
    "    oofs.append(o)\n",
    "\n",
    "cmp=pd.DataFrame(rows).sort_values(\"oof_auc\",ascending=False)\n",
    "display(cmp)\n",
    "cmp.to_csv(ROOT_DIR/\"model_comparison.csv\",index=False)\n",
    "\n",
    "ens=subs[0].join(subs[1],how=\"inner\").join(subs[2],how=\"inner\")\n",
    "ens[\"y\"]=ens.mean(axis=1); ens[[\"y\"]].reset_index().to_csv(ROOT_DIR/\"submission_ensemble_mean.csv\",index=False)\n",
    "\n",
    "oof_ens=oofs[0].join(oofs[1],how=\"inner\").join(oofs[2],how=\"inner\")\n",
    "oof_ens[\"oof\"]=oof_ens.mean(axis=1)\n",
    "base=pd.DataFrame({ID_COL:pd.read_csv(TRAIN_PATH)[ID_COL].values,TARGET_COL:pd.read_csv(TRAIN_PATH)[TARGET_COL].values}).set_index(ID_COL)\n",
    "full=base.join(oof_ens,how=\"inner\"); auc_ens=roc_auc_score(full[TARGET_COL].values, full[\"oof\"].values)\n",
    "print(\"Ensemble OOF AUC:\", auc_ens)\n",
    "full.reset_index()[[ID_COL,\"oof\",TARGET_COL]].to_csv(ROOT_DIR/\"oof_ensemble.csv\",index=False)\n",
    "\n",
    "fig,ax=plt.subplots(); RocCurveDisplay.from_predictions(full[TARGET_COL].values, full[\"oof\"].values, ax=ax)\n",
    "ax.set_title(\"Ensemble OOF ROC\"); fig.savefig(ROOT_DIR/\"figs\"/\"oof_ensemble_roc.png\",bbox_inches=\"tight\"); plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base (3.9.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
